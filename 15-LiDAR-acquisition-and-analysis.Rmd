# LiDAR Acquisition and Analysis {#LiDAR-acquisition-and-analysis}

::: {.box-content .learning-objectives-content}
::: {.box-title .learning-objectives-top}
#### Learning Objectives {.unnumbered}
:::

1.  Understand what LiDAR is and how it works
2.  Understand what we can do with LiDAR data, and what products we can produce
3.  Understand the basic processing steps required to use LiDAR data for forestry and ecological analysis
:::

### Key Terms {.unnumbered}

Light Detection and Ranging (LiDAR), Surface Models, LiDAR Metrics, Area-Based Approach (ABA), Individual Tree Crown (ITC) Detection

## What is LiDAR?

LiDAR stands for **Li**ght **D**etection **A**nd **R**anging (sometimes written as lidar, or LIDAR), and is an active remote sensing technology. A laser scanner and time of flight principles are used to collect 3 dimensional (3D) data. A LiDAR system is made up of three components; a laser-scanning device, an accurate global navigation satellite system (GNSS), and an inertial measurement unit (IMU). The GNSS receiver allows the position of the laser to be determined in space, while the IMU records the orientation of the laser (i.e. roll, pitch, and yaw). Figure \@ref(fig:15-LiDAR-System) shows all of the necessary components of a LiDAR system. When discussing LiDAR in an airborne context (i.e. the unit is being flown), we can call it airborne laser scanning (ALS).

```{r 15-LiDAR-System, fig.cap = fig_cap, out.width="60%", echo = FALSE}
    fig_cap <- paste("Overview of the components of a LiDAR System. As is common for large scale data acquisition, the laser scanning is placed on board an aircarft and scans the Earth below it. The aircraft has on on board GPS/GNSS, as well as an intertial measurement unit (IMU). A GPS base station can be used to post-process data and increase spatial accuracy. CREDIT")
    knitr::include_graphics(here::here("images","15-LiDAR-System.png"))
```

### How Does it Work?

Typical LiDAR systems use the time of flight method to produce 3D data. A laser ranging instrument produces a short, intense pulse of light from the instrument to a target being measured. Some of this energy is then reflected back to the instrument, where it is recorded (as seen in Figure \@ref(fig:15-Concept-of-LiDAR). Since the speed of light, and the location of the laser ranging instrument is known, we can calculate the position of the target by timing how long it takes between the the pulse being emitted and received. If we shoot many pulses of light towards a target, we can create a 3D point cloud of our target (see Figure \@ref(fig:15-las-denoise) for an example of a forest scene). Modern LiDAR systems can shoot hundreds of thousands of pulses per second, which means LiDAR point clouds can contain millions of points, and be several gigabytes large.

```{r 15-Concept-of-LiDAR, fig.cap = fig_cap, out.width="80%", echo = FALSE}
fig_cap <- paste("Concept of LiDAR. A light signal is emitted by the scanner and reflected off the target. CREDIT")
knitr::include_graphics(here::here("images", "15-Concept-of-LiDAR.png"))
```

Since a LiDAR point cloud is a file containing the three dimensional location of points representing objects on the Earth's surface, there are several parameters to take note of. It is important to know what the technical specifications of the data collection parameters were (for example, how many points per square meter do we have?), and how the data was collected (what plaform was used?). A LiDAR dataset includes several pieces of information for each 3D point. `X,Y,Z` location data is included, as well as a GPS time stamp for each point (`gpstime`). Additional information such as `return number`, `scan angle`, `classification`, and `intensity` are also included with the file. We will discuss these concepts in more detail below.

The most common file format for LiDAR files is called the LAS file format (`.las`). This file format was originally designed for 3-dimensional point cloud data, and is a free alternative to proprietary systems or a generic ASCII file interchange system. The main benefits of this file format are that it is relatively quick, can be used by any system, and stores information specific to the nature of LiDAR data without being overly complex (CITE ASPRS website). More information regarding the file type specifications can be found [here](https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities){target="_blank"}.

```{r 15-las-denoise, fig.cap = fig_cap, out.width="80%", echo = FALSE}
fig_cap <- paste("An example of a typical LiDAR point cloud containing 3.14 million points at approximately 80 p/m^2^. The point cloud shows a 200 x 200 meter portion of Pacific Spirit Regional Park in Vancouver, and is part of the 2018 City of Vancouver [dataset](https://opendata.vancouver.ca/explore/dataset/lidar-2018/).")
knitr::include_graphics(here::here("images", "15-las-denoise.png"))
```

## LiDAR History and Use

LiDAR for forestry and ecology can be used to monitor vegetation structure, stream properties, and topography among other uses. Early LiDAR point densities were low (1-5 p/m^2^), which limited researchers to area based measurements of forest volume and biomass in the 1980s (CITE NELSON 2013). These limitations were primarily due to the LiDAR sensor, as well as data storage difficulties. Technological improvements such as increased pulse rates and smaller footprints (leading to increased point density), and increased storage capacity have allowed researchers to look as individual trees as well as whole forests (CITE Jakubowski 2013). Previously limited to static LiDAR sensors, ALS point cloud densities of 1000 p/m^2^ are now entirely feasible. Figure \@ref(fig:15-high-low-point-density
) shows two different point clouds densities, and how difficult it can be to delineate individual tree research at low point densities.

```{r 15-high-low-point-density, fig.cap = fig_cap, out.width="80%", echo = FALSE}
fig_cap <- paste("A cross section of a high density point cloud (A, 80 p/m^2^), and a lower density point cloud (B, 1 p/m^2^).")
knitr::include_graphics(here::here("images", "15-high-low-point-density.png"))
```

Unlike passive remote sensing technologies, LiDAR has the advantage of being able penetrate forest canopies; this means that we are able to detect the ground. LiDAR can be used to map and examine man-made and natural environments, as the data is extremely precise. It can be used in hazard assessment, forestry, agriculture, wet area mapping, and geologic mapping. In this chapter, we will discuss it's use primarily in a forestry context, where it can be used for volume and biomass estimation, as well as individual tree crown analyses.

-   *MORE? - link to some example free/open case studies?*

## Components of a LiDAR System

### Lasers

Lasers are a very important component of LiDAR systems. Here we will discuss some basic concepts, as well as the technical parameters that are important when interpreting LiDAR data. LiDAR lasers are typically beams of near-infrared light (e.g. 1064 nm)(4:10 - video 1), and are used because these wavelengths are considered eye safe. Green wavelengths are used for bathymetric LiDAR (i.e. water penetrating LiDAR), but are less common, and not typically used on land (video 1). Laser scanners use rotating or oscillating mirrors in order to 'scan' a scene in multiple dimensions (video 2 - 1:00). When these scanners are placed on a moving platform (e.g. a plane), we can cover large areas (video 2, 2:08). LiDAR sensors scan in a variety of ways; zig-zag, rotation mirror line, and push broom scanners are the most common, and use the same principles as those described for sensors in Chapter X (video 2).

*Beam divergence* is a property that refers to how wide the light beam becomes when it intercepts an object, and can be used to differentiate LiDAR instruments. Small-footprint LiDAR describes beam diameters intercepting the suface at \< 1m, while large-footprint intercepts the surface at around 5-25m (FIND CITATION). Small-footprint LiDAR is primarily what is used commercially, and has high accuracy, as well as the ability to produce high sampling densities.

-   *Create figure showing beam divergence and scan angle? - too much info?*

The amount of energy that is reflected off an object and back to the sensor is known as *intensity*. Target reflectivity is not directly related to the LiDAR laser itself, but influences whether the return has enough intensity to register with the LiDAR sensor. In addition to surfaces having different properties, the angle of incidence of the laser also affects how much energy the sensor receives. This is known as *scan angle* and is customizable, but lower scan angles are generally preferred. Commercial LiDAR units on airplanes typically have stronger lasers than drone mounted or mobile laser scanners, which allows them to fly higher and cover more area.

All LiDAR sensors emit pulses at a certain rate (*pulse rate*), which can be given as pulses/second, or hertz (Hz). Pulse rate is highly variable (and often programmable on sensors), and along with *scan rate* (the number of scan lines per second) and *flight speed* is responsible for what density a point cloud can be. In the early 2000's 80 000 pulses/second was common; now we can emit up to 260 000 pulses/second or more (CITE). All of this information means that each LiDAR data acquisition campaign has the potential to be rather unique, and the parameter listed above in bold need to be taken into account when doing analysis. All of these factors together affect how an individual pulse interacts with the target.

Several technical aspects of lasers are recorded by the instrument (and usually provided as a flight summary or flight specifications by vendors), while some of it can also be found in the `las` file. We can usually find information that impacts the entire flight in the flight specifications, such as flight height, scan rate, and beam divergence. These aspects shouldn't change for the entire duration of the flight. In contrast, information located in the `las` file affects individual points. Here we can find information such as scan angle, return number, and intensity.

```{r 15-LiDAR-Unit, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("An example of a LiDAR Unit. CREDIT")
knitr::include_graphics(here::here("images", "15-LiDAR-Unit.jpg"))
```

### Position and Orientation

**Global Navigation Satellite Systems**

In order for us to use the calculation from Figure \@ref(fig:15-Concept-of-LiDAR), we need to know the exact position of the scanner in space. For airborne and mobile platforms, we can can do this by using an on board global positioning system (GPS), as well as post processing using local GPS reference station. This helps us to improve accuracy by not comparing our position to a known local position in order to ensure our location is known as accurately as possible. GPS concepts are covered further in Chapter 4.

```{r 15-XYZ-coordinates, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("An on board GPS is required toprovide an accurate location of the LiDAR scanner in space. CREDIT")
knitr::include_graphics(here::here("images", "15-XYZ-coordinates.jpg"))
```

**Inertial Measurement Unit (IMU)**

An inertial measurement unit (IMU) consists of gyroscopes and accelerometers and measures the attitude and acceleration of the aircraft along the X, Y, Z axis. This data is combined with the GNSS data to provide a precise location of the scanner in space. This information becomes very important for airborne platforms where wind conditions can cause the orientation of the scanner to change subtly. We refer to the orientation of the platform in space by using the terms pitch, roll, and yaw, to describe which was the scanner is facing (see \@ref(fig:15-LiDAR-System)).

**Clocks**

LiDAR point data needs to be synced with positioning data in order to know exactly where the point is in space. To do this, a very accurate GPS clock is used to time stamp the laser scanning data (7:30 video 2). Accurate clocks are imperative for producing accurate point clouds; one nanosecond (i.e. one billionth of a second) corresponds to a 30 cm travel distance (as seen in Figure \@ref(fig:15-LiDAR-Discrete-Full-Waveform))! (video 1)

### Platform

LiDAR units can be attached to a variety of platforms. Traditionally, LiDAR units for forestry research were mounted on airplanes and helicopters, as units were large and cumbersome, however ground based units such as terrestrial laser scanning (TLS), and mobile laser scanning (MLS) have also been developed. These units tend to have a very high point density, and TLS is often used in modeling tree architecture.

**Airplanes and Helicopters**

Airplanes and helicopters are still the most common platforms for LiDAR data collection. This is due to their ability to collect large amounts of data in one acquisition. LiDAR units that are designed for airplanes are more powerful than those designed for drones, leading to increased penetration in forests, even though the flight height is significantly increased. Data storage issues can also be mitigated as the platform is not as sensitive to weight restrictions when compared to drones. With increased pulse rates, data acquisitions can also be dense enough to do individual tree crown work. Typical point densities range from 5-200 p/m^2^.

**Drone**

As laser units have decreased in size, we have been able to mount LiDAR units to smaller platforms. Drones (also known as unmanned aerial vehicles (UAV) or remotely piloted aerial systems (RPAS)) are extremely convenient to collect high density point clouds over small areas. They typically fly relatively close to the forest (e.g. 50m above the trees) and fly a predined flight route so ensure evenly spaced data collection. Typical point densities range from hundreds to thousands of points per meter squared. A major limitation of drones is currently battery life, as acquisition campaigns are limited by how long the drone can fly for (approximately 20 minutes). This means that collecting large amounts of data is difficult in remote locations.

```{r 15-LiDAR-on-Drone-2, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("Drone mounted LiDAR. This technology is rapidly developing, with many companies working towards creating units capable of acquiring high density datasets over large areas. CREDIT")
knitr::include_graphics(here::here("images", "15-LiDAR-on-Drone-2.jpg"))
```

**Mobile Laser Scanning**

Mobile Laser Scanning (MLS) includes people (sometimes called 'backpack LiDAR') and moving vehicles. This version of LiDAR have been used by transportation and engineering companies to precisely map things like road or building conditions, and as the units have reduced in size there has been and increase in interest for use in forestry. Current MLS units such as panel 2 in Figure \@ref(fig:15-LiDAR-Platforms) can be carried around by the user in a forest easily. [Specs from Spencer for GeoSLAM]. Typical point densities are in the hundreds to thousands of points per meter squared. This is highly dependent on what the MLS is mounted to!

**Terrestrial Laser Scanning**

Terrestrial Laser Scanning (TLS) is a static system. These units are used by engineers for surveying, and are used by foresters to precisely measure trees. This information can be used to build Quantitative structure models (QSM), to precisely estimate tree parameters. Unlike the other platforms mentioned here, TLS is not necessarily a fast data collection technique. Due to occlusion, the TLS instrument needs to be placed in multiple positions around a plot to be able to fully visualize the trees, which means that a plot can take [**cite how long a plot can take**] to survey! Typical point densities are in the thousands of points per meter squared.

**Satellite**

The last platform that LiDAR units are used for is on satellites. The two major satellite LiDAR systems are ICESat, and GEDI. - ICESat **FIND MORE REFERENCES**

```{r 15-LiDAR-Platforms, fig.cap = fig_cap, out.width="90%", echo = FALSE}
fig_cap <- paste("LiDAR Platforms 1:SOURCE, 2:SOURCE, 3:SOURCE, 4:SOURCE.")
knitr::include_graphics(here::here("images", "15-LiDAR-Platforms.png"))
```

## Types of LiDAR

### Discrete Return

Discrete return LiDAR is currently most common type of LiDAR.

Include figure of a cross-section! 1:10 in video 3 - energy detected from the return has to meet a certain threshold to become a return Classified returns by the arrival sequence - e.g. 1st return = high canopy, or ground if there is no vegetation

### Full Waveform

Issue of data storage - now becoming a viable alternative. Look at Figure \@ref(fig:15-LiDAR-Discrete-Full-Waveform) for example 3:00 video 3 - record complete signal at high sampling rates for further processing

```{r 15-LiDAR-Discrete-Full-Waveform, fig.cap = fig_cap, out.width="80%", echo = FALSE}
fig_cap <- paste("Differents in the response between discrete echo and full waveform LiDAR.")
knitr::include_graphics(here::here("images", "15-LiDAR-Discrete-Full-Waveform.png"))
```

### Emerging Technology

**Multispectral**

-   New.. Titan Optech system?
-   What use could this have
-   NCC slides

**Single Photon Lidar**

-   New - requires less power.
-   NCC slides

::: {.box-content .call-out-content}
::: {.box-title .call-out-top}
#### Call out {.unnumbered}
:::

<p>

Specifications for LiDAR data acquisitions are highly variable. It is important to know what type of LiDAR you are using, and to understand the technical specifications before diving into any analysis.

</p>
:::

## LiDAR Derivatives and Analysis

LiDAR point clouds require post-processing to be useful. Often, point clouds contain noise that needs to be removed, while the points need to be classified to produce derivatives. Once a point cloud has been cleaned and classified, we can create a variety of products to describe the Earth's surface, as well as describe vertical characteristics of our point clouds.

-   **MORE?** - brief sentence on what kinds of derivatives are commonly produced...

### Bare Earth Elevation

Digital elevation models (DEMs) represent the Earth's surface. Using a classified point cloud, we can isolate the points that are categorized as ground (`Classification == 2`) and create a raster that represents the ground. DEMs are also called digital terrain models (DTMs), although a DTM can include vector features that represent natural features (CHECK). DEMs have a variety of uses, from terrain modeling for watersheds, to road design (CITE: lidR book). In addition to being used on their own, DEMs can be used to normalize point clouds; this is the process of subtracting the ground elevation from a point cloud in order to place the points on a flat plane, so that each point represents the height above the ground, not absolute height. To create a DEM, various interpolation techniques are available - these techniques are covered in more detail in Chapter X, but common algorithms include inverse distance weighting (IDW), kriging, and k-nearest neighbour (KNN).

When creating a DEM from a LiDAR point cloud, there are a few important considerations to make. The first is what resolution the DEM should be created with. The density of the point cloud is what dictates this; if the density of a point cloud is low, there is a lower likelihood of a point representing the ground. This means that a lower resolution DEM should be created. Conversely, high density point clouds can produce higher density DEMs. Additionally, forest/vegetation type is important. Dense, coastal forests in BC are likely to have high canopy cover (and therefore fewer ground points) than the more sparse subalpine forests in the province's interior.

```{r 15-las-dem, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("A digital elevation model (DEM) produced from LiDAR")
knitr::include_graphics(here::here("images", "15-las-dem.png"))
```

### Digital Surface Model and Canopy Height Models

Digital surface models (DSMs) represent surface features. In contrast to a DEM, the DSM captures the natural and built features of the environment, and can be thought of as a table cloth placed over a scene. When a point cloud is normalized, the derived surface can be called a canopy height model (CHM), as the layer represents the upper canopy height at a given resolution. While the elevation values are different, both surfaces are derived using the same algorithms (CITE lidR BOOK).

```{r 15-las-CHM-2D, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("A canopy height model (CHM), also known as a digital surface model (DSM) produced from LiDAR")
knitr::include_graphics(here::here("images", "15-las-CHM-2D.png"))
```

### Area Based Approach vs. Individual Tree Crown Approach

LiDAR analysis in forestry uses two broad approaches, an area-based approach (ABA), or an individual tree detection approach (ITD). The ITD approach locates individual trees and allows the estimation of individual tree heights and crown area. From this, other metrics such as stem diameter, number of stems, basal area and stem volume can be derived (Hyyppä and Inkinen 1999). In contrast, the main goal of an ABA is to generate wall-to-wall estimates of inventory attributes, such as mean height, dominant height, mean diameter, stem number, basal area, and volume of the stands (Næsset 2002). WHen doing these analyses, we produce LiDAR metrics. These metrics are descriptive statistics from the point cloud over a unit area. How we define that unit is decides what kind of analysis we are able to do, and what kind of inferences are possible (i.e. ABA vs ITD).

-   *Add some examples of studies using ABA* - study by Tristan or Piotr?

```{r 15-las-hmax-2D, fig.cap = fig_cap, out.width="70%", echo = FALSE}
fig_cap <- paste("Maximum heights of 10 meter cells using an area-based approach.")
knitr::include_graphics(here::here("images", "15-las-hmax-2D.png"))
```

### Tree Segmentation

Tree segmentation is becoming operationally relevant as LiDAR systems become more advanced. Tree segmentation is an attempt to extract individual trees from a point cloud. Since point clouds do not include information regarding what point belongs to which tree, we need to classify the points, in a similar way to how we would classify points that represent the ground.

```{r 15-Processing-Flowchart, fig.cap = fig_cap, out.width="90%", echo = FALSE}
fig_cap <- paste("A typical LiDAR processing workflow. After acquiring data, pre-processing is necessary to clean and normalize the point cloud. After this a CHM can be created to detect tree tops, before segmentating the point cloud based on these points." )
knitr::include_graphics(here::here("images", "15-Processing-Flowchart.png"))
```

Once we have segmented a point cloud, we can produce metrics for individual trees.

-   *What can you do with individual trees*

```{r 15-las-treetops, fig.cap = fig_cap, out.width="80%", echo = FALSE}
fig_cap <- paste("Example of tree tops detected using the `find_trees` function." )
knitr::include_graphics(here::here("images", "15-las-treetops.png"))
```

### Software and Analysis Tools

As LiDAR acquisition becomes cheaper, more tools are becoming available to do analysis. In this chapter, we use [lidR](https://cran.r-project.org/web/packages/lidR/){target="_blank"}; a free and open source R package that can be used for the entire process of analyzing a point cloud. Several other options exist, such as [A Shiny-based Application for Extracting Forest Information from LiDAR data](https://github.com/carlos-alberto-silva/weblidar-treetop){target="_blank"} (also in R), the [Digital-Forestry-Toolbox](http://mparkan.github.io/Digital-Forestry-Toolbox/){target="_blank"} which is available for MATLAB, or [FUSION](http://forsys.cfr.washington.edu/fusion/fusion_overview.html){target="_blank"}, a software developed by the USDA Forest Service. Paid software is also frequently used in LiDAR processing (examples include [ArcGIS Pro](https://pro.arcgis.com/en/pro-app/latest/help/data/las-dataset/use-lidar-in-arcgis-pro.htm){target="_blank"}, and [LAStools](https://rapidlasso.com/lastools/){target="_blank"}), although the cost can be prohibitive. Finally, the open source software [CloudCompare](https://www.danielgm.net/cc/){target="_blank"} can be incredibly useful for both viewing and manually clipping/editing point clouds.

::: {.box-content .case-study-content}
::: {.box-title .case-study-top}
#### Case Study {.unnumbered}
:::

#### Creating LiDAR Metrics from a Raw Point Cloud {#box-text .unnumbered}

<p>

For this case study, we will be using a clipped .las file from the 2018 open [LiDAR dataset](https://opendata.vancouver.ca/explore/dataset/lidar-2018/information/){target="_blank"} of the City of Vancouver and UBC Endowment Lands in British Columbia (we randomly selected a 200 x 200 meter portion of the '4840E_54550N' tile using CloudCompare), and the `lidR` package in R. The script to process this data is included HERE [where to include script?], and you can use the `lidR` [book](https://jean-romain.github.io/lidRbook/){target="_blank"} to get a more in depth understanding of the functions we apply below.

</p>

<p>

The first step when looking at LiDAR data is to inspect it; we recommend using the free software CloudCompare, or the `plot()` function in the `lidR` package. Once we have a sense of our data, we can clean and filter the data, using `classify_noise()` and the '-drop' switch to get rid of the noise in our dataset. Our cleaned dataset can then be used to create a DEM; first we need to classify ground points (`classify_ground()`), followed by using the `grid_terrain()` function in order to rasterize our new ground points. This is an essential step that could require quite a bit of tweaking depending on what you want to use the DEM for! In our case, the DEM is used to *normalize* the point cloud. Normalization removes the effect of terrain on above ground measurements, allowing comparisons of vegetation heights (as can see in the very uniform point cloud in Figure \@ref(fig:15-las-normalize).

```{r 15-las-normalize, fig.cap = fig_cap, out.width="60%", echo = FALSE}
fig_cap <- paste("A normalized point cloud." )
knitr::include_graphics(here::here("images", "15-las-normalize.png"))
```

</p>

<p>

The normalized point cloud is used to create our CHM (created using `grid_canopy()`). It is at this point that we can analyze the point cloud in a variety of ways. We can use an area-based approach (ABA) to create metrics at the grid level (`grid_metrics()`), or we can derive metrics at the individual tree scale. In order to do this we need to first segment the trees (`segment_trees()`) before creating metrics (`tree_metrics()`). Below we can see an example of a segmented point cloud.

```{r 15-las-segmented, fig.cap = fig_cap, out.width="60%", echo = FALSE}
fig_cap <- paste("A segmented point cloud using the algorithm based on Dalponte and Coomes (2016)")
knitr::include_graphics(here::here("images", "15-las-segmented.png"))
```

</p>

<p>

Creating metrics at these two scales are the fundamental way in which we currently think about analysing forests using LiDAR. Each tells us different things about the forest, so it is important to take scale into account when choosing what kind of analysis you want to do. Below we can see a Leaflet map of some area based metrics created for this point cloud!

</p>
:::

### Your Turn! {.unnumbered}

In Figure \@ref(fig:15-map) below, explore some of the LiDAR derivatives that we produced in the case study above. We can see how the pattern for maximum height follows the mean height quite closely. In addition, we can see that the 15th percentile of heights (zq15) also broadly follows this pattern. However, we can see that the standard deviation of heights in the tall areas are quite variable, and that very little ground is visible in our tile (as pzabove2 is very high almost everywhere)

```{r 15-files, echo=FALSE, warning=FALSE, include =FALSE}

# Load library
library(leaflet)
library(raster)
library(sf)
library(sp)
library(htmlwidgets)
library(rgdal)
library(leafem)
library(geojsonio)


# Load files
r_hmean <- raster(here::here("data", "hmean_large.tif")) #mean height
r_hmax <- raster(here::here("data", "hmax_large.tif")) #max height
r_hsd <- raster(here::here("data", "hsd_large.tif")) #standard deviation
r_hzq15 <- raster(here::here("data", "hzq15_large.tif")) #height of 15th percentile of points 
r_hpabove2 <- raster(here::here("data", "hpzabove2_large.tif")) #percent of points above 2 meters

# Set colors and legend titles
pal1 <- colorNumeric(c("viridis"), values(r_hmean),
                    na.color = "transparent")
pal2 <- colorNumeric(c("viridis"), values(r_hmax),
                    na.color = "transparent")
pal3 <- colorNumeric(c("viridis"), values(r_hsd),
                     na.color = "transparent")
pal4 <- colorNumeric("viridis", values(r_hzq15),
                     na.color = "transparent")
pal5 <- colorNumeric("viridis", values(r_hpabove2),
                     na.color = "transparent")

# Add projection information
crs(r_hmean) <- "+proj=utm +zone=10 +datum=NAD83 +units=m"
crs(r_hmax) <- "+proj=utm +zone=10 +datum=NAD83 +units=m"
crs(r_hsd) <- "+proj=utm +zone=10 +datum=NAD83 +units=m"
crs(r_hzq15) <- "+proj=utm +zone=10 +datum=NAD83 +units=m"
crs(r_hpabove2) <- "+proj=utm +zone=10 +datum=NAD83 +units=m"

#create leaflet
m = leaflet() %>%
  addProviderTiles("Esri.WorldImagery") %>% #http://leaflet-extras.github.io/leaflet-providers/preview/
  addScaleBar(position = c("bottomleft")) %>%

  addRasterImage(r_hmean, colors = pal1, group = "Mean Height", opacity = 1, maxBytes = "Inf")%>%
  addRasterImage(r_hmax, colors = pal2, group = "Maximum Height", opacity = 1, maxBytes = "Inf")%>%
  addRasterImage(r_hsd, colors = pal3, group = "Standard Deviation of Height", opacity = 1, maxBytes = "Inf")%>%
  addRasterImage(r_hzq15, colors = pal4, group = "ZQ 15", opacity = 1, maxBytes = "Inf")%>%
  addRasterImage(r_hpabove2, colors = pal5, group = "PZAbove2", opacity = 1, maxBytes = "Inf")%>%
  
  addLegend(pal = pal1, values = values(r_hmean), group = "Mean Height",
            opacity = 1,
            title = "Mean")%>%
  addLegend(pal = pal2, values = values(r_hmax), group = "Maximum Height",
            opacity = 1,
            title = "Maximum")%>%
  addLegend(pal = pal4, values = values(r_hzq15), group = "ZQ 15",
            opacity = 1,
            title = "ZQ 15")%>%
  addLegend(pal = pal3, values = values(r_hsd), group = "Standard Deviation of Height",
            opacity = 1,
            title = "Standard Deviation")%>%
  addLegend(pal = pal5, values = values(r_hpabove2), group = "PZAbove2",
            opacity = 1,
            title = "PZAbove2")%>%

  addLayersControl(overlayGroups = c("Mean Height", "Maximum Height", "ZQ 15",
                                     "Standard Deviation of Height","PZAbove2"),
                   position = c("topleft"),
                   options = layersControlOptions(collapsed = TRUE))%>% 
  hideGroup(c("Maximum Height", "ZQ 15", "Standard Deviation of Height","PZAbove2"))
  
```

```{r 15-map, echo=FALSE, fig.cap = fig_cap}

fig_cap <- paste("Explore different area-based metrics produced in the case study above. Hover over tile icon (top left) to turn different layers on or off.")
knitr::opts_chunk$set(fig.width = 12, fig.height = 12) #make the interactive maps bigger/smaller across the document
m

```

## Summary

LiDAR! Requires 3 components. Important for vertical characterization of the forest. Can produce useful rasters

### Reflection Questions {.unnumbered}

1.  What are the three main components of a LiDAR system?
2.  Why is LiDAR so useful for forestry operations compared to other remote sensing technologies?
3.  ?

### Practice Questions {.unnumbered}

1.  Define the equation that tells us how far a pulse has traveled?
2.  What is meant by the term 'discrete return'?
3.  How is a DEM created? What steps are needed?

`r if (knitr::is_html_output()) ' ## Recommended Readings {-} '`

"A best practices guide for generating forest inventory attributes from airborne laser scanning data using an area-based approach. Information Report FI-X-010"

Ensure all inline citations are properly referenced here.

```{r include=FALSE}
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'htmlwidgets', 'webshot', 'DT',
  'miniUI', 'tufte', 'servr', 'citr', 'rticles'
), 'packages.bib')
```
